#  RuleBookReaserch

## Folder structure 


```text
project_root/
├── src/                     # Python code (Flask app, PDF processing, embedding generation)
│   ├── static/              # Pictures
│   ├── template/            # index.html file
│   python files/            # source code files
├── data/                     # Rulebooks, embeddings, fine-tuned model tracking
│   ├── pdfs/                # Original rulebooks in PDF format
│   ├── extracted/            # Text extracted from PDFs (generated by app)
│   ├── GT/                    # Ground truth files (manual rules, if available)
│   ├── vector_store.faiss     # Embedding index (generated by app)
│   ├── embedding_metadata.json # Metadata for embeddings (generated by app)
│   ├── fine_tuned_model.json  # Tracks your latest fine-tuned model
│   ├── fine_tune_archive/     # Archives of past fine-tuning datasets
│
├── Dockerfile                # Instructions to build the app container
├── docker-compose.yml        # Easy container orchestration
├── .env.template              # Sample environment file
├── README.md                  # This file
```

## Start the app
Create .env file from .env.template and fill with OPENAI API TOKEN and Neon database URL. 

Then run it:
```bash
docker-compose up --build -d
```
Finally go to:
```bash
http://localhost:5000
```

# Run embedai functions
To use embedari functionalities run container then you can run command inside it like that:
```bash
docker exec -it rulebookmaster_app python3 embedai.py make-embedding
```

## Stop the app
```bash
docker-compose down
```

#### TODO
Change fine_tuned_model.json to save model name insted of model id.
